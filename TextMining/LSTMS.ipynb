{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        self.hidden, self.cell = self.initHidden()\n",
    "        x = self.embedding(inp).view(inp.shape[1],1,-1)\n",
    "        out, (h_n, c_n) = self.lstm(x, (self.hidden, self.cell))\n",
    "        return out, h_n, c_n\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size), torch.zeros(1,1,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([1,2,3,4],dtype=torch.long).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(5, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, h_n, c_n = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2033,  0.0575, -0.1110,  0.0744,  0.3849,  0.0932, -0.0111,\n",
       "           0.0138, -0.0621, -0.0169]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0953,  0.0944, -0.1214, -0.0330, -0.2039, -0.2101,  0.0898,\n",
       "          -0.0486, -0.0505,  0.1225]],\n",
       "\n",
       "        [[-0.2406,  0.1974, -0.1025, -0.0595,  0.0978, -0.2167, -0.0358,\n",
       "           0.1241,  0.0753, -0.0253]],\n",
       "\n",
       "        [[-0.0697,  0.0398, -0.1469,  0.1155,  0.0534, -0.1221,  0.1848,\n",
       "           0.1335, -0.0780,  0.1834]],\n",
       "\n",
       "        [[ 0.2033,  0.0575, -0.1110,  0.0744,  0.3849,  0.0932, -0.0111,\n",
       "           0.0138, -0.0621, -0.0169]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3813,  0.1633, -0.2301,  0.1286,  0.5635,  0.1839, -0.0198,\n",
       "           0.0178, -0.1376, -0.0393]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, layers):\n",
    "        super(Model, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers=layers)\n",
    "    \n",
    "    def forward(self, inp, batch_size):\n",
    "        self.hidden, self.cell = self.initHidden(batch_size)\n",
    "        x = self.embedding(inp).view(inp.shape[1],inp.shape[0],-1)\n",
    "        out, (h_n, c_n) = self.lstm(x, (self.hidden, self.cell))\n",
    "        return out, h_n, c_n\n",
    "    \n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(self.layers,batch_size,self.hidden_size), torch.zeros(self.layers,batch_size,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2 = torch.LongTensor([[0,1,2,3],[1,2,3,4],[0,2,1,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(6, 10, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out,h_n,c_n = model(inp_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can deal with packinging variable sized seqiuences in one batch using \"pack_padded_sequence\" and \"pad_packed_sequence\" in pytorch.\n",
    "You can consult this nice article \n",
    "https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
